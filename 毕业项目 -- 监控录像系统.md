毕业项目 -- 监控录像系统



因为工作中一直都是使用C和C++，没有合适的改造项目，之前工作一直在做监控系统中的录像服务，就由此设想一下毕业项目吧



作为一个录像系统，需要提供以下服务：

- 支持手动录像、定时录像以及周期录像
- 录像记录写入数据库进行保存，并且录像进度需要实时更新，考虑到秒级播放，录像进度需要1s更新一次
- 录像查询，支持按照监控点以及时间段进行查询
- 录像服务所在机器的各种性能参数的搜集以及日志的搜集



![流程图 (1)](/Users/admin/Downloads/流程图 (1).jpg)

1. 录像任务管理服务

   - 管理手动录像任务
   - 根据周期录像计划，生成录像任务
   - 根据定时录像计划，生成录像任务
   - 通过录像网关下发录像任务

2. 录像服务网关

   - 监控各个录像服务的性能指标
   - 接收到录像任务后，根据录像服务的负载情况，调度录像服务执行录像任务

3. 录像服务

   - 接收录像任务，向监控前端拉取码流并写入文件
   - 在成功打开文件并拉取码流后，向kafka写入新增录像记录事件，此处可以考虑进行聚合
   - 考虑到存储满后的录像覆盖，一般一个小时会切换文件进行录像，因此在一个小时后，关闭当前录像文件时，触发一次当前录像记录结束的事件，写入kafka
   - 持续写入录像的媒体数据过程中，考虑客户对于录像的秒开需求，1s需要更新一次录像进度。考虑到更新的频率，不易直接写数据库，因此可以将进度信息写入redis集群
   - 有录像记录查询请求时，如果查询的是1小时内的录像记录，优先考虑查询redis，redis中没有的再考虑查询mysql数据库，否则可以考虑直接查询mysql
   - 录像服务运行过程中的日志写入本地日志文件

   考虑到需要同时支持大规模的监控点位同时录像，因此录像服务必须根据并发录像任务情况进行分布式的集群部署

4. 录像记录JOB

   - 接收到新增录像记录的事件，从redis中获取录像记录的详细信息（文件名，开始时间等）并写入mysql，同时启动周期任务，周期的从redis中获取该录像记录的进度信息，更新mysql中的录像记录信息
   - 接收到录像记录结束事件，从redis中获取录像记录的进度信息，更新mysql中的录像记录，并停止周期任务

5. 日志

   - 在每台录像服务的机器上部署一个filebeat，采集录像服务的本地日志文件，并写入kafka
   - logstash从kafka中获取日志进行过滤，并写入ElasticSearch
   - 最后通过Kibana展示录像服务的日志
